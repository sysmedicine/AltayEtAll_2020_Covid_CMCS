{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPLEMENTARY DATASETS\n",
    "\n",
    "**BOLD DATASETS ARE RAW DATA, YOU MUST HAVE THOSE TO RUN THE PIPELINE**\n",
    "\n",
    "**Dataset S1 The characteristics of each patient involved in the study.**\n",
    "\n",
    "Dataset S2 Summary of laboratory and physical variables before and after treatment in the CMCS treated and placebo groups.\n",
    "\n",
    "**Dataset S3 Untargeted metabolomics data for each patient before and after treatment.**\n",
    "\n",
    "Dataset S4 Plasma level of metabolites that are significantly different on Days 14 vs Day 0 in the CMCS and placebo groups. Only metabolites detected in >50% of samples were analyzed. \n",
    "\n",
    "Dataset S5 Plasma level of metabolites that are significantly different between the CMCS and placebo groups on Days 0 and Day 14. Only metabolites detected in >50% of samples were analyzed.\n",
    "\n",
    "Dataset S6 Association between the plasma level all metabolites with the plasma levels of metabolic cofactors including serine, carnitine, nicotinamide riboside, and cysteine as well as degradation products of hydroxychloroquine including hydroquinone sulfate and 2-methoxyhydroquinone sulfate (1).\n",
    "\n",
    "**Dataset S7 The Olink multiplex inflammation panel used to detect the dynamic range of 72 proteins in plasma samples of the 93 patients participated in the study.**\n",
    "\n",
    "Dataset S8 Plasma level of inflammation related proteins that are significantly different on Days 14 vs Day 0 in the CMCS and placebo groups. Only proteins detected in >50% of samples were analyzed.\n",
    "\n",
    "Dataset S9 Plasma level of inflammation related proteins that are significantly different between the CMCS and placebo groups on Days 0 and Day 14. Only metabolites detected in >50% of samples were analyzed. \n",
    "\n",
    "Dataset S10 Association between the plasma level all inflammation related proteins with the plasma levels of metabolic cofactors including serine, carnitine, nicotinamide riboside, and cysteine.\n",
    "\n",
    "Dataset S11 Association between the plasma level of clinical variables including ALT, AST, LDH, Triglycerides (TGs) and hemoglobin with plasma level of all metabolites.\n",
    "\n",
    "Dataset S12 Association between the plasma level of clinical variables including ALT, AST, LDH, Triglycerides (TGs) and hemoglobin with plasma level of all inflammation related proteins.\n",
    "\n",
    "Dataset S13 Multi-Omics Network Data, including edges and nodes information. The network is presented in the iNetModels (http://inetmodels.com).\n",
    "\n",
    "Dataset S14 Association between the plasma level of key inflammation related proteins including MCP-4, IL-18R1, HGF, CXCL10 and CSF-1 with plasma level of all metabolites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr,ttest_ind,ttest_rel\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import numpy as np\n",
    "import leidenalg, os, pickle\n",
    "import igraph as ig\n",
    "\n",
    "def convert_decimals_and_text(series):\n",
    "    return series.astype(str).str.replace('<','').str.replace('>','').str.replace('10.000.00','10000').str.replace(',','.').replace('-',np.nan).astype(float)\n",
    "\n",
    "format_fig = 'pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Altay et al Dataset 1.xlsx', header=1,index_col=0).dropna(how='all')\n",
    "data_day0 = temp.iloc[0:, (temp.columns.tolist().index('DAY-0')+1):temp.columns.tolist().index('DAY-14')].apply(convert_decimals_and_text)\n",
    "data_day14 = temp.iloc[0:, (temp.columns.tolist().index('DAY-14')+1):-2].apply(convert_decimals_and_text)\n",
    "data_day0.index = data_day0.index.astype(int) \n",
    "data_day14.index = data_day14.index.astype(int) \n",
    "data_day14.columns=data_day0.columns\n",
    "metadata = temp['GROUP'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_day0 = data_day0.reindex(metadata[metadata == 'CMCS'].index)\n",
    "p_day0 = data_day0.reindex(metadata[metadata == 'Placebo'].index)\n",
    "t_day14 = data_day14.reindex(metadata[metadata == 'CMCS'].index)\n",
    "p_day14 = data_day14.reindex(metadata[metadata == 'Placebo'].index)\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data_day0.columns:\n",
    "    print(i)\n",
    "    res.append([i,\n",
    "                '%.2f ± %.2f' % (p_day0[i].mean(),p_day0[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day0[i].mean(),t_day0[i].std()),\n",
    "                '%.2f ± %.2f' % (p_day14[i].mean(),p_day14[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day14[i].mean(),t_day14[i].std()),\n",
    "                np.log2(t_day0[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/p_day14[i].mean()),\n",
    "                np.log2(p_day14[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/t_day0[i].mean()),\n",
    "                \n",
    "                ttest_ind(t_day0[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_ind(t_day14[i],p_day14[i], nan_policy='omit')[1],\n",
    "                ttest_rel(p_day14[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_rel(t_day14[i],t_day0[i], nan_policy='omit')[1]\n",
    "               ])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Measurement', \n",
    "                                'Mean ± SD (Placebo - Day 0)', \n",
    "                                'Mean ± SD (Active - Day 0)', \n",
    "                                'Mean ± SD (Placebo - Day 14)', \n",
    "                                'Mean ± SD (Active - Day 14)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 0)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 14)',\n",
    "                                'Log2FoldChange (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'Log2FoldChange (Active - Day 14 vs Active - Day 0)', \n",
    "                                'P-Value (Active vs Placebo - Day 0)',\n",
    "                                'P-Value (Active vs Placebo - Day 14)',\n",
    "                                'P-Value (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'P-Value (Active - Day 14 vs Active - Day 0)'\n",
    "                               ]).set_index('Measurement')\n",
    "res.to_excel('../ResultsPaper/DS/Altay et al Dataset 2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabolomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Altay et al Dataset 3.xlsx')\n",
    "metadata = temp.parse('Metadata',index_col = 0)\n",
    "data = temp.parse('Volume & Batch Normalized',index_col = 0).T\n",
    "mapping = temp.parse('Mapping Metabolites',index_col = 0)\n",
    "ID_dict = metadata['SUBJECT_ID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_day0 = data.reindex(metadata[metadata['GROUP_ID'].str.contains('v1')].index)\n",
    "data_day0.index = [ID_dict[i] for i in data_day0.index]\n",
    "data_day14 = data.reindex(metadata[metadata['GROUP_ID'].str.contains('v2')].index)\n",
    "data_day14.index = [ID_dict[i] for i in data_day14.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_day0 = data_day0.reindex(metadata[metadata['CODE'] == 'Active']['SUBJECT_ID'])\n",
    "p_day0 = data_day0.reindex(metadata[metadata['CODE'] == 'Placebo']['SUBJECT_ID'])\n",
    "t_day14 = data_day14.reindex(metadata[metadata['CODE'] == 'Active']['SUBJECT_ID'])\n",
    "p_day14 = data_day14.reindex(metadata[metadata['CODE'] == 'Placebo']['SUBJECT_ID'])\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data_day0.columns:\n",
    "    res.append([i,\n",
    "                '%.2f ± %.2f' % (p_day0[i].mean(),p_day0[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day0[i].mean(),t_day0[i].std()),\n",
    "                '%.2f ± %.2f' % (p_day14[i].mean(),p_day14[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day14[i].mean(),t_day14[i].std()),\n",
    "                np.log2(t_day0[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/p_day14[i].mean()),\n",
    "                np.log2(p_day14[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/t_day0[i].mean()),\n",
    "                \n",
    "                ttest_ind(t_day0[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_ind(t_day14[i],p_day14[i], nan_policy='omit')[1],\n",
    "                ttest_rel(p_day14[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_rel(t_day14[i],t_day0[i], nan_policy='omit')[1]\n",
    "               ])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Measurement', \n",
    "                                'Mean ± SD (Placebo - Day 0)', \n",
    "                                'Mean ± SD (Active - Day 0)', \n",
    "                                'Mean ± SD (Placebo - Day 14)', \n",
    "                                'Mean ± SD (Active - Day 14)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 0)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 14)',\n",
    "                                'Log2FoldChange (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'Log2FoldChange (Active - Day 14 vs Active - Day 0)', \n",
    "                                'P-Value (Active vs Placebo - Day 0)',\n",
    "                                'P-Value (Active vs Placebo - Day 14)',\n",
    "                                'P-Value (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'P-Value (Active - Day 14 vs Active - Day 0)'\n",
    "                               ]).set_index('Measurement')\n",
    "res['FDR (Active vs Placebo - Day 0)']=multipletests(res['P-Value (Active vs Placebo - Day 0)'],method='fdr_bh')[1]\n",
    "res['FDR (Active vs Placebo - Day 14)']=multipletests(res['P-Value (Active vs Placebo - Day 14)'],method='fdr_bh')[1]\n",
    "res['FDR (Placebo - Day 14 vs Placebo - Day 0)']=multipletests(res['P-Value (Placebo - Day 14 vs Placebo - Day 0)'],method='fdr_bh')[1]\n",
    "res['FDR (Active - Day 14 vs Active - Day 0']=multipletests(res['P-Value (Active - Day 14 vs Active - Day 0)'],method='fdr_bh')[1]\n",
    "\n",
    "pd.concat([res[res.columns[res.columns.str.contains('Mean') | ~res.columns.str.contains('Active vs Placebo')]],mapping.reindex(res.index)],1).set_index('CHEMICAL_NAME').to_excel('../ResultsPaper/DS/Altay et al Dataset 4.xlsx')\n",
    "pd.concat([res[res.columns[res.columns.str.contains('Mean') | res.columns.str.contains('Active vs Placebo')]],mapping.reindex(res.index)],1).set_index('CHEMICAL_NAME').to_excel('../ResultsPaper/DS/Altay et al Dataset 5.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Altay et al Dataset 7.xlsx')\n",
    "metadata = temp.parse('Metadata',index_col = 0).set_index('SampleName')\n",
    "data = temp.parse('NPX',index_col = 0)\n",
    "data_day0 = data.reindex(metadata[metadata['VISIT'].str.contains('Day 0')].index)\n",
    "data_day14 = data.reindex(metadata[metadata['VISIT'].str.contains('Day 14')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_day0 = data_day0.reindex(metadata[metadata['Group'] == 'CMCS'].index).dropna(how='all')\n",
    "p_day0 = data_day0.reindex(metadata[metadata['Group'] == 'Placebo'].index).dropna(how='all')\n",
    "t_day14 = data_day14.reindex(metadata[metadata['Group'] == 'CMCS'].index).dropna(how='all')\n",
    "p_day14 = data_day14.reindex(metadata[metadata['Group'] == 'Placebo'].index).dropna(how='all')\n",
    "t_day0.index = [i.replace('_day0','') for i in t_day0.index]\n",
    "p_day0.index = [i.replace('_day0','') for i in p_day0.index]\n",
    "t_day14.index = [i.replace('_day14','') for i in t_day14.index]\n",
    "p_day14.index = [i.replace('_day14','') for i in p_day14.index]\n",
    "\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in data_day0.columns:\n",
    "    res.append([i,\n",
    "                '%.2f ± %.2f' % (p_day0[i].mean(),p_day0[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day0[i].mean(),t_day0[i].std()),\n",
    "                '%.2f ± %.2f' % (p_day14[i].mean(),p_day14[i].std()), \n",
    "                '%.2f ± %.2f' % (t_day14[i].mean(),t_day14[i].std()),\n",
    "                np.log2(t_day0[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/p_day14[i].mean()),\n",
    "                np.log2(p_day14[i].mean()/p_day0[i].mean()),\n",
    "                np.log2(t_day14[i].mean()/t_day0[i].mean()),\n",
    "                \n",
    "                ttest_ind(t_day0[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_ind(t_day14[i],p_day14[i], nan_policy='omit')[1],\n",
    "                ttest_rel(p_day14[i],p_day0[i], nan_policy='omit')[1],\n",
    "                ttest_rel(t_day14[i],t_day0[i], nan_policy='omit')[1]\n",
    "               ])\n",
    "\n",
    "res = pd.DataFrame(res,columns=['Measurement', \n",
    "                                'Mean ± SD (Placebo - Day 0)', \n",
    "                                'Mean ± SD (Active - Day 0)', \n",
    "                                'Mean ± SD (Placebo - Day 14)', \n",
    "                                'Mean ± SD (Active - Day 14)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 0)',\n",
    "                                'Log2FoldChange (Active vs Placebo - Day 14)',\n",
    "                                'Log2FoldChange (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'Log2FoldChange (Active - Day 14 vs Active - Day 0)', \n",
    "                                'P-Value (Active vs Placebo - Day 0)',\n",
    "                                'P-Value (Active vs Placebo - Day 14)',\n",
    "                                'P-Value (Placebo - Day 14 vs Placebo - Day 0)', \n",
    "                                'P-Value (Active - Day 14 vs Active - Day 0)'\n",
    "                               ]).set_index('Measurement')\n",
    "res['FDR (Active vs Placebo - Day 0)']=multipletests(res['P-Value (Active vs Placebo - Day 0)'],method='fdr_bh')[1]\n",
    "res['FDR (Active vs Placebo - Day 14)']=multipletests(res['P-Value (Active vs Placebo - Day 14)'],method='fdr_bh')[1]\n",
    "res['FDR (Placebo - Day 14 vs Placebo - Day 0)']=multipletests(res['P-Value (Placebo - Day 14 vs Placebo - Day 0)'],method='fdr_bh')[1]\n",
    "res['FDR (Active - Day 14 vs Active - Day 0']=multipletests(res['P-Value (Active - Day 14 vs Active - Day 0)'],method='fdr_bh')[1]\n",
    "\n",
    "\n",
    "\n",
    "res[res.columns[res.columns.str.contains('Mean') | ~res.columns.str.contains('Active vs Placebo')]].to_excel('../ResultsPaper/DS/Altay et al Dataset 8.xlsx')\n",
    "res[res.columns[res.columns.str.contains('Mean') | res.columns.str.contains('Active vs Placebo')]].to_excel('../ResultsPaper/DS/Altay et al Dataset 9.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Analysis:\n",
    "    def __init__(self,raw_data,nodes,respath):\n",
    "        self.res_path=respath\n",
    "        self.writer = pd.ExcelWriter('%s/Altay et al Dataset 13.xlsx' % self.res_path, engine='xlsxwriter')\n",
    "        self.network_ori=self.__calc(raw_data)\n",
    "        self.nodes=nodes\n",
    "        print('Network Analysis')\n",
    "        self.__net_analysis_combi()\n",
    "        self.writer.save()\n",
    "    \n",
    "    def __calc(self,df):\n",
    "        print('Calculating Correlation..')\n",
    "        temp=spearmanr(df.T, nan_policy='omit')\n",
    "        corr=pd.DataFrame(temp[0],columns=list(df.index),index=list(df.index))\n",
    "        pval=pd.DataFrame(temp[1],columns=list(df.index),index=list(df.index))\n",
    "        print('Filtering the matrix Correlation..')\n",
    "        corr=corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "        pval=pval.where(np.triu(np.ones(pval.shape)).astype(np.bool))\n",
    "        print('Making long table of Correlation..')\n",
    "        corr2=corr.unstack().reset_index(name='weight')\n",
    "        pval2=pval.unstack().reset_index(name='pval')\n",
    "        res=corr2.merge(pval2,on=['level_0','level_1'])\n",
    "        res=res[res['level_0'] != res['level_1']]\n",
    "        res=res.dropna()\n",
    "        res=res[['level_0','level_1','weight','pval']]\n",
    "        res['padj']=multipletests(res['pval'],method='fdr_bh')[1]\n",
    "        res.columns=['source','target','correlation','pvalue']\n",
    "        res.to_excel(self.writer, sheet_name='Edges (Unfiltered)', index = False)\n",
    "        res=res[res.padj < 0.05].reset_index(drop=True)\n",
    "        res.columns=['source','target','correlation','pvalue','padj']\n",
    "        res=res[['source','target','correlation','pvalue','padj']]\n",
    "        print('Done!!')\n",
    "        return res\n",
    "    \n",
    "    def __net_analysis_combi(self):\n",
    "        print('Loading The Network...')\n",
    "        temp=self.network_ori\n",
    "        g= ig.Graph.TupleList(zip(temp['source'],temp['target'],temp['correlation']),weights=True)\n",
    "        self.network = g\n",
    "        G_pos = g.subgraph_edges(g.es.select(weight_gt = 0), delete_vertices=False)\n",
    "        G_neg = g.subgraph_edges(g.es.select(weight_lt = 0), delete_vertices=False)\n",
    "        G_neg.es['weight'] = [-w for w in G_neg.es['weight']]\n",
    "        part_pos = leidenalg.ModularityVertexPartition(G_pos, weights='weight')\n",
    "        part_neg = leidenalg.ModularityVertexPartition(G_neg, weights='weight');\n",
    "        optimiser = leidenalg.Optimiser()\n",
    "        diff = optimiser.optimise_partition_multiplex([part_pos, part_neg],layer_weights=[1,-1], n_iterations=-1)\n",
    "        self.clustering_combi=pd.DataFrame(pd.Series(part_pos.membership+part_neg.membership,index=G_pos.vs['name']+G_neg.vs['name'])).reset_index().drop_duplicates().set_index('index')[0]\n",
    "        print('Cluster Analysis...')\n",
    "        self.modularity_combi=diff\n",
    "        self.nodes['cluster'] = self.clustering_combi.reindex(self.nodes.index).tolist()\n",
    "        self.nodes.to_excel(self.writer, sheet_name='Nodes')\n",
    "    \n",
    "    def save_network(self):\n",
    "        print('Saving The Network..')\n",
    "        pickle_out = open('%s/network_object.pkl' % self.res_path,\"wb\")\n",
    "        self.writer = None\n",
    "        pickle.dump(self, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('../ResultsPaper/DS/Altay et al Dataset 1.xlsx', header=1,index_col=0).dropna(how='all')\n",
    "data_day0 = temp.iloc[0:, (temp.columns.tolist().index('DAY-0')+1):temp.columns.tolist().index('DAY-14')].apply(convert_decimals_and_text)\n",
    "data_day14 = temp.iloc[0:, (temp.columns.tolist().index('DAY-14')+1):-2].apply(convert_decimals_and_text)\n",
    "data_day0.index = ['Patient_'+str(i)+'_day0' for i in data_day0.index.astype(int) ]\n",
    "data_day14.index = ['Patient_'+str(i)+'_day14' for i in data_day14.index.astype(int) ]\n",
    "data_day14.columns=data_day0.columns\n",
    "data_clin = pd.concat([data_day0,data_day14]).T\n",
    "\n",
    "temp = pd.ExcelFile('../ResultsPaper/DS/Altay et al Dataset 7.xlsx')\n",
    "data_prots = temp.parse('NPX',index_col = 0).T\n",
    "\n",
    "temp = pd.ExcelFile('../ResultsPaper/DS/Altay et al Dataset 3.xlsx')\n",
    "metadata_mets = temp.parse('Metadata',index_col = 0)\n",
    "metadata_mets['name'] = ('Patient'+'_'+metadata_mets['SUBJECT_ID'].astype(str)+'_'+metadata_mets['VISIT']).str.replace('v1','day0').replace('v2','day14')\n",
    "data_mets = temp.parse('Volume & Batch Normalized',index_col = 0)\n",
    "mapping_mets = temp.parse('Mapping Metabolites',index_col = 0)\n",
    "ID_dict = metadata_mets['name'].to_dict()\n",
    "data_mets.columns = [ID_dict[i] for i in data_mets.columns]\n",
    "\n",
    "data=pd.concat([data_mets,data_prots,data_clin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_mets = mapping_mets.copy()\n",
    "nodes_mets['LOC'] = 'METABOLITE'\n",
    "nodes_prots = pd.DataFrame(pd.Series(data_prots.index, index = data_prots.index, name = \"CHEMICAL_NAME\"))\n",
    "nodes_prots['LOC'] = 'PROTEIN'\n",
    "nodes_clin = pd.DataFrame(pd.Series(data_clin.index, index = data_clin.index, name = \"CHEMICAL_NAME\"))\n",
    "nodes_clin['LOC'] = 'CLINICAL'\n",
    "nodes = pd.concat([nodes_mets,nodes_prots,nodes_clin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#AVOID RUNNING THIS UNLESS NECESSARY\n",
    "############\n",
    "\n",
    "# print('StartingNet')\n",
    "\n",
    "# k=Network_Analysis(raw_data=data,nodes=nodes,respath='../ResultsPaper/DS/')\n",
    "# k.save_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with Specific Analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.ExcelFile('../ResultsPaper/DS/Altay et al Dataset 13.xlsx')\n",
    "edges = temp.parse('Edges (Unfiltered)')\n",
    "nodes = temp.parse('Nodes',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mets = ['serine','carnitine','nicotinamide riboside','cysteine','2-methoxyhydroquinone sulfate (1)','hydroquinone sulfate']\n",
    "selected_clin = ['Alanine aminotransferase (U/L)','Aspartate transaminase (U/L)','Lactate dehydrogenase (U/L)','Triglyceride (mg/dL)','Hemoglobin (g/dL)']\n",
    "#prelim prots they are significant in active day 14 vs 0, and also within top 10 most central proteins in the network\n",
    "selected_prots = ['CXCL10','CSF-1','IL-18R1','MCP-4','HGF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = 'CHEMICAL_NAME'\n",
    "neigh = 'METABOLITE'\n",
    "nodes_mapping = nodes[name_col].to_dict()\n",
    "temp_metn = nodes[nodes[name_col].isin(selected_mets)]\n",
    "temp_mete = {}\n",
    "for i in temp_metn.index:\n",
    "    name = nodes_mapping[i]\n",
    "    temp1 = edges[(edges['source'] == i) & edges['target'].isin(nodes[nodes['LOC'] == neigh].index)][['target','correlation','pval']]\n",
    "    temp1.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp2 = edges[(edges['target'] == i) & edges['source'].isin(nodes[nodes['LOC'] == neigh].index)][['source','correlation','pval']]\n",
    "    temp2.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp_fin = pd.concat([temp1,temp2])\n",
    "    temp_fin['Metabolites'] = temp_fin['Metabolites'].replace(nodes_mapping)\n",
    "    temp_fin['FDR']=multipletests(temp_fin['P-Value'],method='fdr_bh')[1]\n",
    "    temp_mete[name] = temp_fin.set_index('Metabolites')\n",
    "pd.concat(temp_mete,keys=temp_mete.keys(),axis = 1).to_excel('../ResultsPaper/DS/Altay et al Dataset 6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = 'CHEMICAL_NAME'\n",
    "neigh = 'PROTEIN'\n",
    "nodes_mapping = nodes[name_col].to_dict()\n",
    "temp_met = nodes[nodes[name_col].isin(selected_mets[0:4])]\n",
    "temp_mete = {}\n",
    "for i in temp_met.index:\n",
    "    name = nodes_mapping[i]\n",
    "    temp1 = edges[(edges['source'] == i) & edges['target'].isin(nodes[nodes['LOC'] == neigh].index)][['target','correlation','pval']]\n",
    "    temp1.columns = ['Proteins', 'Correlation', 'P-Value']\n",
    "    temp2 = edges[(edges['target'] == i) & edges['source'].isin(nodes[nodes['LOC'] == neigh].index)][['source','correlation','pval']]\n",
    "    temp2.columns = ['Proteins', 'Correlation', 'P-Value']\n",
    "    temp_fin = pd.concat([temp1,temp2])\n",
    "    temp_fin['Proteins'] = temp_fin['Proteins'].replace(nodes_mapping)\n",
    "#     temp_fin['FDR']=multipletests(temp_fin['P-Value'],method='fdr_bh')[1]\n",
    "    temp_mete[name] = temp_fin.set_index('Proteins')\n",
    "pd.concat(temp_mete,keys=temp_mete.keys(),axis = 1).to_excel('../ResultsPaper/DS/Altay et al Dataset 10.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = 'CHEMICAL_NAME'\n",
    "neigh = 'METABOLITE'\n",
    "nodes_mapping = nodes[name_col].to_dict()\n",
    "temp_met = nodes[nodes[name_col].isin(selected_clin)]\n",
    "temp_mete = {}\n",
    "for i in temp_met.index:\n",
    "    name = nodes_mapping[i]\n",
    "    temp1 = edges[(edges['source'] == i) & edges['target'].isin(nodes[nodes['LOC'] == neigh].index)][['target','correlation','pval']]\n",
    "    temp1.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp2 = edges[(edges['target'] == i) & edges['source'].isin(nodes[nodes['LOC'] == neigh].index)][['source','correlation','pval']]\n",
    "    temp2.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp_fin = pd.concat([temp1,temp2])\n",
    "    temp_fin['Metabolites'] = temp_fin['Metabolites'].replace(nodes_mapping)\n",
    "    temp_fin['FDR']=multipletests(temp_fin['P-Value'],method='fdr_bh')[1]\n",
    "    temp_mete[name] = temp_fin.set_index('Metabolites')\n",
    "pd.concat(temp_mete,keys=temp_mete.keys(),axis = 1).to_excel('../ResultsPaper/DS/Altay et al Dataset 11.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = 'CHEMICAL_NAME'\n",
    "neigh = 'PROTEIN'\n",
    "nodes_mapping = nodes[name_col].to_dict()\n",
    "temp_met = nodes[nodes[name_col].isin(selected_clin)]\n",
    "temp_mete = {}\n",
    "for i in temp_met.index:\n",
    "    name = nodes_mapping[i]\n",
    "    temp1 = edges[(edges['source'] == i) & edges['target'].isin(nodes[nodes['LOC'] == neigh].index)][['target','correlation','pval']]\n",
    "    temp1.columns = ['Proteins', 'Correlation', 'P-Value']\n",
    "    temp2 = edges[(edges['target'] == i) & edges['source'].isin(nodes[nodes['LOC'] == neigh].index)][['source','correlation','pval']]\n",
    "    temp2.columns = ['Proteins', 'Correlation', 'P-Value']\n",
    "    temp_fin = pd.concat([temp1,temp2])\n",
    "    temp_fin['Proteins'] = temp_fin['Proteins'].replace(nodes_mapping)\n",
    "    temp_fin['FDR']=multipletests(temp_fin['P-Value'],method='fdr_bh')[1]\n",
    "    temp_mete[name] = temp_fin.set_index('Proteins')\n",
    "pd.concat(temp_mete,keys=temp_mete.keys(),axis = 1).to_excel('../ResultsPaper/DS/Altay et al Dataset 12.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = 'CHEMICAL_NAME'\n",
    "neigh = 'METABOLITE'\n",
    "nodes_mapping = nodes[name_col].to_dict()\n",
    "temp_met = nodes[nodes[name_col].isin(selected_prots)]\n",
    "temp_mete = {}\n",
    "for i in temp_met.index:\n",
    "    name = nodes_mapping[i]\n",
    "    temp1 = edges[(edges['source'] == i) & edges['target'].isin(nodes[nodes['LOC'] == neigh].index)][['target','correlation','pval']]\n",
    "    temp1.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp2 = edges[(edges['target'] == i) & edges['source'].isin(nodes[nodes['LOC'] == neigh].index)][['source','correlation','pval']]\n",
    "    temp2.columns = ['Metabolites', 'Correlation', 'P-Value']\n",
    "    temp_fin = pd.concat([temp1,temp2])\n",
    "    temp_fin['Metabolites'] = temp_fin['Metabolites'].replace(nodes_mapping)\n",
    "    temp_fin['FDR']=multipletests(temp_fin['P-Value'],method='fdr_bh')[1]\n",
    "    temp_mete[name] = temp_fin.set_index('Metabolites')\n",
    "pd.concat(temp_mete,keys=temp_mete.keys(),axis = 1).to_excel('../ResultsPaper/DS/Altay et al Dataset 14.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
